
Files already downloaded and verified
Examples shape: torch.Size([16, 9, 105, 105, 1]), Labels shape: torch.Size([16, 9]), Target shape: torch.Size([16, 17])
Target: tensor([[556,   0, 468,   0, 468,   0, 802,   0, 802,   0, 578,   0, 802,   0,
         468,   0, 802],
        [506,   0, 506,   0, 123,   0, 137,   0, 123,   0, 123,   0, 301,   0,
         506,   0, 123],
        [ 50,   0, 939,   0,  26,   0, 190,   0,  50,   0, 939,   0,  50,   0,
         939,   0,  50],
        [172,   0, 399,   0, 956,   0, 934,   0, 863,   0, 312,   0, 900,   0,
         383,   0, 657],
        [538,   0, 192,   0, 192,   0, 759,   0, 759,   0, 759,   0, 258,   0,
         192,   0, 192],
        [695,   0, 763,   0, 763,   0, 703,   0, 695,   0, 763,   0, 695,   0,
         708,   0, 763],
        [694,   0, 706,   0, 123,   0, 152,   0, 152,   0, 706,   0, 152,   0,
         706,   0, 152],
        [385,   0, 385,   0, 385,   0, 533,   0, 620,   0, 182,   0, 182,   0,
         182,   0, 385],
        [240,   0, 174,   0, 230,   0, 230,   0, 240,   0, 230,   0, 652,   0,
         240,   0, 240],
        [395,   0, 216,   0,  50,   0, 395,   0, 898,   0, 216,   0, 395,   0,
         216,   0, 216],
        [780,   0, 839,   0, 506,   0, 780,   0, 780,   0, 150,   0, 839,   0,
         839,   0, 780],
        [566,   0, 392,   0, 566,   0,   5,   0,   5,   0,   5,   0, 689,   0,
         566,   0,   5],
        [812,   0, 857,   0, 821,   0, 857,   0, 857,   0, 812,   0, 908,   0,
         812,   0, 812],
        [177,   0, 464,   0, 106,   0, 742,   0, 713,   0, 715,   0, 356,   0,
         787,   0, 500],
        [892,   0, 892,   0, 537,   0, 960,   0, 537,   0,   5,   0, 537,   0,
         892,   0, 537],
        [368,   0,  17,   0, 187,   0,  90,   0, 512,   0, 910,   0, 135,   0,
         196,   0, 224]], dtype=torch.int32)
x.shape: torch.Size([16, 9, 1, 105, 105])
Preds shape: torch.Size([16, 9, 1623])
Target one hot shape: torch.Size([16, 17, 1623])
Target one hot symmetric: False
Traceback (most recent call last):
  File "/Users/starfarmer2/Desktop/Jasper/Coding Files/CSPlus/ICL-Experiments/./experiment_resnet.py", line 71, in <module>
    experiment_base(dataset)
  File "/Users/starfarmer2/Desktop/Jasper/Coding Files/CSPlus/ICL-Experiments/./experiment_resnet.py", line 61, in experiment_base
    trainer.train()
  File "/Users/starfarmer2/Desktop/Jasper/Coding Files/CSPlus/ICL-Experiments/train_resnet.py", line 105, in train
    losses_all = criterion(preds, target_one_hot)
  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1164, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 3014, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected target size [16, 1623], got [16, 17, 1623]